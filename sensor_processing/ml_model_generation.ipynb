{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "american-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#needed imports from Pandas, Numpy, Pickle, Matplot, Keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "if os.path.exists(\"best_model.pkl\"): os.remove(\"best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "opposed-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading raw data\n",
    "path = 'MovementAAL/new_dataset/stream_0000'\n",
    "sequences = list()\n",
    "\n",
    "for i in range (1,9):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    values = df.values\n",
    "    sequences.append(values)\n",
    "\n",
    "path = 'MovementAAL/new_dataset/stream_000'\n",
    "\n",
    "for i in range(10, 99):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    sequences.append(values)\n",
    "\n",
    "#path = 'MovementAAL/new_dataset/stream_00'\n",
    "\n",
    "#for i in range(100, 200):\n",
    " #   file_path = path + str(i) + '.csv'\n",
    "   # df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    #sequences.append(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "difficult-tension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#target values\n",
    "targets = pd.read_csv('MovementAAL/new_dataset/MovementAAL_target.csv')\n",
    "targets = targets.values[:100,1]\n",
    "print(len(targets))\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "great-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "#Loading grouping\n",
    "groups = pd.read_csv('MovementAAL/groups/MovementAAL_DatasetGroup.csv', header=0)\n",
    "groups = groups.values[:100,1]\n",
    "print(len(groups))\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "announced-signature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    97.0\n",
      "mean     55.0\n",
      "std       0.0\n",
      "min      55.0\n",
      "25%      55.0\n",
      "50%      55.0\n",
      "75%      55.0\n",
      "max      55.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "len_sequences = []\n",
    "for one_seq in sequences:\n",
    "    len_sequences.append(len(one_seq))\n",
    "print(pd.Series(len_sequences).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "broken-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding the sequence with the values in last row to max length\n",
    "to_pad = 55\n",
    "new_seq = []\n",
    "for one_seq in sequences:\n",
    "    len_one_seq = len(one_seq)\n",
    "    last_val = one_seq[-1]\n",
    "    n = to_pad - len_one_seq\n",
    "   \n",
    "\n",
    "    to_concat = np.repeat(one_seq[-1], n).reshape(9, n).transpose()\n",
    "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
    "    new_seq.append(new_one_seq)\n",
    "final_seq = np.stack(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "encouraging-rabbit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1. -1. -2. ... -2. -1. -2.]\n",
      "  [ 0. -1. -2. ... -2. -1. -1.]\n",
      "  [-1. -1. -2. ... -2.  0. -1.]\n",
      "  ...\n",
      "  [ 0.  0. -2. ... -2. -2. -1.]\n",
      "  [ 0.  0. -3. ... -2. -2.  0.]\n",
      "  [ 0. -1. -3. ... -3. -2.  0.]]\n",
      "\n",
      " [[ 0.  0. -2. ... -4. -3.  0.]\n",
      "  [ 0.  0. -1. ... -1. -2. -1.]\n",
      "  [ 0.  0.  0. ... -1. -1. -1.]\n",
      "  ...\n",
      "  [-1.  0.  0. ... -4. -1. -1.]\n",
      "  [-1. -1.  0. ... -4. -1. -2.]\n",
      "  [-1. -1.  0. ... -3. -1. -2.]]\n",
      "\n",
      " [[ 0.  1.  0. ... -1. -2. -2.]\n",
      "  [ 0.  1. -1. ... -1.  0. -2.]\n",
      "  [ 0.  0. -1. ... -1.  0. -2.]\n",
      "  ...\n",
      "  [ 1.  1. -1. ... -3. -1. -1.]\n",
      "  [ 1.  0. -1. ... -3. -2.  0.]\n",
      "  [ 0.  0. -1. ... -3. -1.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]]\n"
     ]
    }
   ],
   "source": [
    "#truncate the sequence to length 60\n",
    "seq_len = 55\n",
    "final_seq=sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float', truncating='post')\n",
    "print(final_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "reverse-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 33 validation 33 test 29 \n",
      " target: train 33 validate 33 test 34\n"
     ]
    }
   ],
   "source": [
    "#Training data based on group 2\n",
    "train = [final_seq[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "#validation data based on group 1\n",
    "validation = [final_seq[i] for i in range(len(groups)) if groups[i]==1]\n",
    "#test data based on group 3\n",
    "test = [final_seq[i] for i in range(len(groups)-5) if groups[i]==3]\n",
    "\n",
    "#train target based on group 2\n",
    "train_target = [targets[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "#validation target based on group 1\n",
    "validation_target = [targets[i] for i in range(len(groups)) if groups[i]==1]\n",
    "#test target based on group 3\n",
    "test_target = [targets[i] for i in range(len(groups)) if groups[i]==3]\n",
    "\n",
    "print('train {} validation {} test {} \\n target: train {} validate {} test {}'.format(len(train), len(validation), len(test), len(train_target), len(validation_target), len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "developed-programming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#creating np.arrays for each dataset\n",
    "train = np.array(train)\n",
    "validation = np.array(validation)\n",
    "test = np.array(test)\n",
    "\n",
    "#training target data\n",
    "train_target = np.array(train_target)\n",
    "print(train_target)\n",
    "\n",
    "#validation target\n",
    "validation_target = np.array(validation_target)\n",
    "\n",
    "#test data and target test\n",
    "test_target = np.array(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "reverse-beatles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 200)               168000    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 168,201\n",
      "Trainable params: 168,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 200)               168000    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 168,201\n",
      "Trainable params: 168,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#adding the LSTM to the model and printing the summary\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(seq_len, 9)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mysterious-airfare",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66 samples, validate on 66 samples\n",
      "Epoch 1/20\n",
      "66/66 [==============================] - 3s 44ms/step - loss: 2.9795e-05 - accuracy: 0.0000e+00 - val_loss: -0.0939 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to best_model.pkl\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 2.3813e-05 - accuracy: 0.0000e+00 - val_loss: -0.0959 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.00000\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.9073e-05 - accuracy: 0.0000e+00 - val_loss: -0.0977 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.00000\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.4421e-05 - accuracy: 0.0000e+00 - val_loss: -0.0991 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.00000\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.1415e-05 - accuracy: 0.0000e+00 - val_loss: -0.1004 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.00000\n",
      "Epoch 6/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 8.6409e-06 - accuracy: 0.0000e+00 - val_loss: -0.1014 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.00000\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 6.6468e-06 - accuracy: 0.0000e+00 - val_loss: -0.1022 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.00000\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.7220e-06 - accuracy: 0.0000e+00 - val_loss: -0.1028 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.00000\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.5083e-06 - accuracy: 0.0000e+00 - val_loss: -0.1033 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.00000\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 3.8436e-06 - accuracy: 0.0000e+00 - val_loss: -0.1036 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.00000\n",
      "Epoch 11/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 3.0055e-06 - accuracy: 0.0000e+00 - val_loss: -0.1039 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.00000\n",
      "Epoch 12/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 3.0922e-06 - accuracy: 0.0000e+00 - val_loss: -0.1041 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.00000\n",
      "Epoch 13/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.9073e-06 - accuracy: 0.0000e+00 - val_loss: -0.1042 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.00000\n",
      "Epoch 14/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.8207e-06 - accuracy: 0.0000e+00 - val_loss: -0.1043 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.00000\n",
      "Epoch 15/20\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.7918e-06 - accuracy: 0.0000e+00 - val_loss: -0.1043 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.00000\n",
      "Epoch 16/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 9.8257e-07 - accuracy: 0.0000e+00 - val_loss: -0.1043 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.00000\n",
      "Epoch 17/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 6.0688e-07 - accuracy: 0.0000e+00 - val_loss: -0.1043 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.00000\n",
      "Epoch 18/20\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 8.3808e-07 - accuracy: 0.0000e+00 - val_loss: -0.1043 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.00000\n",
      "Epoch 19/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.0693e-06 - accuracy: 0.0000e+00 - val_loss: -0.1042 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.00000\n",
      "Epoch 20/20\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.6473e-06 - accuracy: 0.0000e+00 - val_loss: -0.1041 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8901da0b50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "chk = ModelCheckpoint('best_model.pkl', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.fit(train, train_target, epochs=20, batch_size=200, callbacks=[chk], validation_data=(validation,validation_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aggressive-sound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test cases is 63\n",
      "[[[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]]\n",
      "length of test predictions is 63\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "length of test_target is 68\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [68, 63]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-44b442827275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length of test_target is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [68, 63]"
     ]
    }
   ],
   "source": [
    "#loading the exported pkl model and testing the accuracy score\n",
    "model = load_model('best_model.pkl')\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = model.predict_classes(test)\n",
    "print('Length of test cases is {}'.format(len(test)))\n",
    "print(test)\n",
    "print('length of test predictions is {}'.format(len(test_preds)))\n",
    "print(test_preds)\n",
    "print('length of test_target is {}'.format(len(test_target)))\n",
    "print(test_target)\n",
    "accuracy_score(test_target, test_preds)\n",
    "print(accuracy_score(test_target, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
