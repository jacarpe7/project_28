{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "american-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#needed imports from Pandas, Numpy, Pickle, Matplot, Keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "if os.path.exists(\"best_model.pkl\"): os.remove(\"best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "opposed-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading raw data\n",
    "path = 'MovementAAL/new_dataset/stream_0000'\n",
    "sequences = list()\n",
    "\n",
    "for i in range (1,9):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    values = df.values\n",
    "    sequences.append(values)\n",
    "\n",
    "path = 'MovementAAL/new_dataset/stream_000'\n",
    "\n",
    "for i in range(10, 99):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    sequences.append(values)\n",
    "\n",
    "path = 'MovementAAL/new_dataset/stream_00'\n",
    "\n",
    "for i in range(100, 200):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    sequences.append(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "difficult-tension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "#target values\n",
    "targets = pd.read_csv('MovementAAL/new_dataset/MovementAAL_target.csv')\n",
    "targets = targets.values[:200,1]\n",
    "print(len(targets))\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "great-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "#Loading grouping\n",
    "groups = pd.read_csv('MovementAAL/groups/MovementAAL_DatasetGroup.csv', header=0)\n",
    "groups = groups.values[:200,1]\n",
    "print(len(groups))\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "announced-signature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    197.0\n",
      "mean      55.0\n",
      "std        0.0\n",
      "min       55.0\n",
      "25%       55.0\n",
      "50%       55.0\n",
      "75%       55.0\n",
      "max       55.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "len_sequences = []\n",
    "for one_seq in sequences:\n",
    "    len_sequences.append(len(one_seq))\n",
    "print(pd.Series(len_sequences).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "broken-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding the sequence with the values in last row to max length\n",
    "to_pad = 55\n",
    "new_seq = []\n",
    "for one_seq in sequences:\n",
    "    len_one_seq = len(one_seq)\n",
    "    last_val = one_seq[-1]\n",
    "    n = to_pad - len_one_seq\n",
    "   \n",
    "\n",
    "    to_concat = np.repeat(one_seq[-1], n).reshape(9, n).transpose()\n",
    "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
    "    new_seq.append(new_one_seq)\n",
    "final_seq = np.stack(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "encouraging-rabbit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1. -1. -2. ... -2. -1. -2.]\n",
      "  [ 0. -1. -2. ... -2. -1. -1.]\n",
      "  [-1. -1. -2. ... -2.  0. -1.]\n",
      "  ...\n",
      "  [ 0.  0. -2. ... -2. -2. -1.]\n",
      "  [ 0.  0. -3. ... -2. -2.  0.]\n",
      "  [ 0. -1. -3. ... -3. -2.  0.]]\n",
      "\n",
      " [[ 0.  0. -2. ... -4. -3.  0.]\n",
      "  [ 0.  0. -1. ... -1. -2. -1.]\n",
      "  [ 0.  0.  0. ... -1. -1. -1.]\n",
      "  ...\n",
      "  [-1.  0.  0. ... -4. -1. -1.]\n",
      "  [-1. -1.  0. ... -4. -1. -2.]\n",
      "  [-1. -1.  0. ... -3. -1. -2.]]\n",
      "\n",
      " [[ 0.  1.  0. ... -1. -2. -2.]\n",
      "  [ 0.  1. -1. ... -1.  0. -2.]\n",
      "  [ 0.  0. -1. ... -1.  0. -2.]\n",
      "  ...\n",
      "  [ 1.  1. -1. ... -3. -1. -1.]\n",
      "  [ 1.  0. -1. ... -3. -2.  0.]\n",
      "  [ 0.  0. -1. ... -3. -1.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]]\n"
     ]
    }
   ],
   "source": [
    "#truncate the sequence to length 60\n",
    "seq_len = 55\n",
    "final_seq=sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float', truncating='post')\n",
    "print(final_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "reverse-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 66 validation 66 test 63 \n",
      " target: train 66 validate 66 test 68\n"
     ]
    }
   ],
   "source": [
    "#Training data based on group 2\n",
    "train = [final_seq[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "#validation data based on group 1\n",
    "validation = [final_seq[i] for i in range(len(groups)) if groups[i]==1]\n",
    "#test data based on group 3\n",
    "test = [final_seq[i] for i in range(len(groups)-5) if groups[i]==3]\n",
    "\n",
    "#train target based on group 2\n",
    "train_target = [targets[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "#validation target based on group 1\n",
    "validation_target = [targets[i] for i in range(len(groups)) if groups[i]==1]\n",
    "#test target based on group 3\n",
    "test_target = [targets[i] for i in range(len(groups)) if groups[i]==3]\n",
    "\n",
    "print('train {} validation {} test {} \\n target: train {} validate {} test {}'.format(len(train), len(validation), len(test), len(train_target), len(validation_target), len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "developed-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating np.arrays for each dataset\n",
    "train = np.array(train)\n",
    "validation = np.array(validation)\n",
    "test = np.array(test)\n",
    "\n",
    "#training target data\n",
    "train_target = np.array(train_target)\n",
    "train_target = (train_target+1)/2\n",
    "\n",
    "#validation target\n",
    "validation_target = np.array(validation_target)\n",
    "validation_target = (validation_target+1)/2\n",
    "\n",
    "#test data and target test\n",
    "test_target = np.array(test_target)\n",
    "test_target = (test_target+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "reverse-beatles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 200)               168000    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 168,201\n",
      "Trainable params: 168,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 200)               168000    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 168,201\n",
      "Trainable params: 168,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#adding the LSTM to the model and printing the summary\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(seq_len, 9)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-airfare",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66 samples, validate on 66 samples\n",
      "Epoch 1/20\n",
      "66/66 [==============================] - 3s 41ms/step - loss: 0.6934 - accuracy: 0.5152 - val_loss: 0.6888 - val_accuracy: 0.5606\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56061, saving model to best_model.pkl\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.6901 - accuracy: 0.5455 - val_loss: 0.7198 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56061\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7133 - accuracy: 0.5000 - val_loss: 0.7119 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.56061\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7073 - accuracy: 0.5000 - val_loss: 0.6904 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.56061\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.6971 - accuracy: 0.4545 - val_loss: 0.6849 - val_accuracy: 0.5909\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.56061 to 0.59091, saving model to best_model.pkl\n",
      "Epoch 6/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6844 - val_accuracy: 0.5758\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.59091\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.6973 - accuracy: 0.5000 - val_loss: 0.6848 - val_accuracy: 0.5758\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.59091\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.6952 - accuracy: 0.4545 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.59091\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6901 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.59091\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.6900 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.59091\n",
      "Epoch 11/20\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 0.6957 - accuracy: 0.4727"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "chk = ModelCheckpoint('best_model.pkl', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.fit(train, train_target, epochs=20, batch_size=55, callbacks=[chk], validation_data=(validation,validation_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aggressive-sound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test cases is 29\n",
      "[[[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]]\n",
      "length of test predictions is 29\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "length of test_target is 34\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [34, 29]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-44b442827275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length of test_target is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [34, 29]"
     ]
    }
   ],
   "source": [
    "#loading the exported pkl model and testing the accuracy score\n",
    "model = load_model('best_model.pkl')\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = model.predict_classes(test)\n",
    "print('Length of test cases is {}'.format(len(test)))\n",
    "print(test)\n",
    "print('length of test predictions is {}'.format(len(test_preds)))\n",
    "print(test_preds)\n",
    "print('length of test_target is {}'.format(len(test_target)))\n",
    "print(test_target)\n",
    "accuracy_score(test_target, test_preds)\n",
    "print(accuracy_score(test_target, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
