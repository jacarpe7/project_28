{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "american-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#needed imports from Pandas, Numpy, Pickle, Matplot, Keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "if os.path.exists(\"best_model.pkl\"): os.remove(\"best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "opposed-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading raw data\n",
    "path = 'MovementAAL/new_dataset/stream_0000'\n",
    "sequences = list()\n",
    "\n",
    "for i in range (1,9):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    values = df.values\n",
    "    sequences.append(values)\n",
    "\n",
    "path = 'MovementAAL/new_dataset/stream_000'\n",
    "\n",
    "for i in range(10, 99):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    sequences.append(values)\n",
    "\n",
    "path = 'MovementAAL/new_dataset/stream_00'\n",
    "\n",
    "for i in range(100, 400):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    sequences.append(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "difficult-tension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "#target values\n",
    "targets = pd.read_csv('MovementAAL/new_dataset/MovementAAL_target.csv')\n",
    "targets = targets.values[:400,1]\n",
    "print(len(targets))\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "great-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "#Loading grouping\n",
    "groups = pd.read_csv('MovementAAL/groups/MovementAAL_DatasetGroup.csv', header=0)\n",
    "groups = groups.values[:400,1]\n",
    "print(len(groups))\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "announced-signature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    397.0\n",
      "mean      55.0\n",
      "std        0.0\n",
      "min       55.0\n",
      "25%       55.0\n",
      "50%       55.0\n",
      "75%       55.0\n",
      "max       55.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "len_sequences = []\n",
    "for one_seq in sequences:\n",
    "    len_sequences.append(len(one_seq))\n",
    "print(pd.Series(len_sequences).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "broken-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding the sequence with the values in last row to max length\n",
    "to_pad = 55\n",
    "new_seq = []\n",
    "for one_seq in sequences:\n",
    "    len_one_seq = len(one_seq)\n",
    "    last_val = one_seq[-1]\n",
    "    n = to_pad - len_one_seq\n",
    "   \n",
    "\n",
    "    to_concat = np.repeat(one_seq[-1], n).reshape(9, n).transpose()\n",
    "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
    "    new_seq.append(new_one_seq)\n",
    "final_seq = np.stack(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "encouraging-rabbit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1. -1. -2. ... -2. -1. -2.]\n",
      "  [ 0. -1. -2. ... -2. -1. -1.]\n",
      "  [-1. -1. -2. ... -2.  0. -1.]\n",
      "  ...\n",
      "  [ 0.  0. -2. ... -2. -2. -1.]\n",
      "  [ 0.  0. -3. ... -2. -2.  0.]\n",
      "  [ 0. -1. -3. ... -3. -2.  0.]]\n",
      "\n",
      " [[ 0.  0. -2. ... -4. -3.  0.]\n",
      "  [ 0.  0. -1. ... -1. -2. -1.]\n",
      "  [ 0.  0.  0. ... -1. -1. -1.]\n",
      "  ...\n",
      "  [-1.  0.  0. ... -4. -1. -1.]\n",
      "  [-1. -1.  0. ... -4. -1. -2.]\n",
      "  [-1. -1.  0. ... -3. -1. -2.]]\n",
      "\n",
      " [[ 0.  1.  0. ... -1. -2. -2.]\n",
      "  [ 0.  1. -1. ... -1.  0. -2.]\n",
      "  [ 0.  0. -1. ... -1.  0. -2.]\n",
      "  ...\n",
      "  [ 1.  1. -1. ... -3. -1. -1.]\n",
      "  [ 1.  0. -1. ... -3. -2.  0.]\n",
      "  [ 0.  0. -1. ... -3. -1.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]]\n"
     ]
    }
   ],
   "source": [
    "#truncate the sequence to length 60\n",
    "seq_len = 55\n",
    "final_seq=sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float', truncating='post')\n",
    "print(final_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "reverse-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 132 validation 132 test 131 \n",
      " target: train 132 validate 132 test 136\n"
     ]
    }
   ],
   "source": [
    "#Training data based on group 2\n",
    "train = [final_seq[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "#validation data based on group 1\n",
    "validation = [final_seq[i] for i in range(len(groups)) if groups[i]==1]\n",
    "#test data based on group 3\n",
    "test = [final_seq[i] for i in range(len(groups)-5) if groups[i]==3]\n",
    "\n",
    "#train target based on group 2\n",
    "train_target = [targets[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "#validation target based on group 1\n",
    "validation_target = [targets[i] for i in range(len(groups)) if groups[i]==1]\n",
    "#test target based on group 3\n",
    "test_target = [targets[i] for i in range(len(groups)) if groups[i]==3]\n",
    "\n",
    "print('train {} validation {} test {} \\n target: train {} validate {} test {}'.format(len(train), len(validation), len(test), len(train_target), len(validation_target), len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "developed-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating np.arrays for each dataset\n",
    "train = np.array(train)\n",
    "validation = np.array(validation)\n",
    "test = np.array(test)\n",
    "\n",
    "#training target data\n",
    "train_target = np.array(train_target)\n",
    "train_target = (train_target+1)/2\n",
    "\n",
    "#validation target\n",
    "validation_target = np.array(validation_target)\n",
    "validation_target = (validation_target+1)/2\n",
    "\n",
    "#test data and target test\n",
    "test_target = np.array(test_target)\n",
    "test_target = (test_target+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "reverse-beatles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 200)               168000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 168,201\n",
      "Trainable params: 168,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 200)               168000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 168,201\n",
      "Trainable params: 168,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#adding the LSTM to the model and printing the summary\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(seq_len, 9)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "mysterious-airfare",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/40\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 1.0002 - accuracy: 0.0000e+00 - val_loss: 0.3104 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.25000, saving model to best_model.pkl\n",
      "Epoch 2/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.3119 - accuracy: 0.2500 - val_loss: -0.2929 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.25000\n",
      "Epoch 3/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -0.2966 - accuracy: 0.2500 - val_loss: -0.8798 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.25000\n",
      "Epoch 4/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -0.8864 - accuracy: 0.2500 - val_loss: -1.4964 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.25000\n",
      "Epoch 5/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -1.5039 - accuracy: 0.2500 - val_loss: -2.1798 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.25000\n",
      "Epoch 6/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -2.1866 - accuracy: 0.2500 - val_loss: -2.9494 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.25000\n",
      "Epoch 7/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -2.9544 - accuracy: 0.2500 - val_loss: -3.7867 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.25000\n",
      "Epoch 8/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -3.7895 - accuracy: 0.2500 - val_loss: -4.6326 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.25000\n",
      "Epoch 9/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -4.6338 - accuracy: 0.2500 - val_loss: -5.4277 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.25000\n",
      "Epoch 10/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -5.4281 - accuracy: 0.2500 - val_loss: -6.1553 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.25000\n",
      "Epoch 11/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -6.1554 - accuracy: 0.2500 - val_loss: -6.8365 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.25000\n",
      "Epoch 12/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -6.8365 - accuracy: 0.2500 - val_loss: -7.4963 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.25000\n",
      "Epoch 13/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -7.4963 - accuracy: 0.2500 - val_loss: -8.1466 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.25000\n",
      "Epoch 14/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -8.1466 - accuracy: 0.2500 - val_loss: -8.7872 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.25000\n",
      "Epoch 15/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -8.7872 - accuracy: 0.2500 - val_loss: -9.4162 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.25000\n",
      "Epoch 16/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -9.4162 - accuracy: 0.2500 - val_loss: -10.0180 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.25000\n",
      "Epoch 17/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -10.0180 - accuracy: 0.2500 - val_loss: -10.5899 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.25000\n",
      "Epoch 18/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -10.5899 - accuracy: 0.2500 - val_loss: -11.1310 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.25000\n",
      "Epoch 19/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -11.1310 - accuracy: 0.2500 - val_loss: -11.6312 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.25000\n",
      "Epoch 20/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -11.6312 - accuracy: 0.2500 - val_loss: -12.0838 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.25000\n",
      "Epoch 21/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -12.0838 - accuracy: 0.2500 - val_loss: -12.4970 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.25000\n",
      "Epoch 22/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -12.4970 - accuracy: 0.2500 - val_loss: -12.8789 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.25000\n",
      "Epoch 23/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -12.8789 - accuracy: 0.2500 - val_loss: -13.2251 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.25000\n",
      "Epoch 24/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -13.2252 - accuracy: 0.2500 - val_loss: -13.5440 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.25000\n",
      "Epoch 25/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -13.5440 - accuracy: 0.2500 - val_loss: -13.8424 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.25000\n",
      "Epoch 26/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -13.8424 - accuracy: 0.2500 - val_loss: -14.1170 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.25000\n",
      "Epoch 27/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -14.1170 - accuracy: 0.2500 - val_loss: -14.3746 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.25000\n",
      "Epoch 28/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -14.3746 - accuracy: 0.2500 - val_loss: -14.6184 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.25000\n",
      "Epoch 29/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -14.6184 - accuracy: 0.2500 - val_loss: -14.8510 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.25000\n",
      "Epoch 30/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -14.8510 - accuracy: 0.2500 - val_loss: -15.0772 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.25000\n",
      "Epoch 31/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -15.0772 - accuracy: 0.2500 - val_loss: -15.2935 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.25000\n",
      "Epoch 32/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -15.2935 - accuracy: 0.2500 - val_loss: -15.5039 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.25000\n",
      "Epoch 33/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -15.5039 - accuracy: 0.2500 - val_loss: -15.7097 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.25000\n",
      "Epoch 34/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -15.7097 - accuracy: 0.2500 - val_loss: -15.9116 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.25000\n",
      "Epoch 35/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -15.9116 - accuracy: 0.2500 - val_loss: -16.1103 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.25000\n",
      "Epoch 36/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -16.1103 - accuracy: 0.2500 - val_loss: -16.3085 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.25000\n",
      "Epoch 37/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -16.3085 - accuracy: 0.2500 - val_loss: -16.5021 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.25000\n",
      "Epoch 38/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -16.5021 - accuracy: 0.2500 - val_loss: -16.6937 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.25000\n",
      "Epoch 39/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -16.6937 - accuracy: 0.2500 - val_loss: -16.8833 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.25000\n",
      "Epoch 40/40\n",
      "132/132 [==============================] - 1s 5ms/step - loss: -16.8833 - accuracy: 0.2500 - val_loss: -17.0712 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.25000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8960116ed0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "chk = ModelCheckpoint('best_model.pkl', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.fit(train, train_target, epochs=40, batch_size=400, callbacks=[chk], validation_data=(validation,validation_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aggressive-sound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test cases is 131\n",
      "[[[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  2. ...  1.  1.  0.]\n",
      "  [ 1.  1.  2. ...  1. -1.  0.]\n",
      "  [ 1.  0.  2. ...  1. -1.  0.]\n",
      "  ...\n",
      "  [ 0. -1. -2. ...  2. -2. -2.]\n",
      "  [ 0. -1.  0. ...  2. -2. -2.]\n",
      "  [ 0. -1.  1. ...  1. -1. -1.]]]\n",
      "length of test predictions is 131\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "length of test_target is 136\n",
      "[1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.5 1.5\n",
      " 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5\n",
      " 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 2.  2.  2.  2.\n",
      " 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      " 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.5 2.5 2.5 2.5 2.5 2.5\n",
      " 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5\n",
      " 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [136, 131]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-44b442827275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length of test_target is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/project_28/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [136, 131]"
     ]
    }
   ],
   "source": [
    "#loading the exported pkl model and testing the accuracy score\n",
    "model = load_model('best_model.pkl')\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = model.predict_classes(test)\n",
    "print('Length of test cases is {}'.format(len(test)))\n",
    "print(test)\n",
    "print('length of test predictions is {}'.format(len(test_preds)))\n",
    "print(test_preds)\n",
    "print('length of test_target is {}'.format(len(test_target)))\n",
    "print(test_target)\n",
    "accuracy_score(test_target, test_preds)\n",
    "print(accuracy_score(test_target, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
