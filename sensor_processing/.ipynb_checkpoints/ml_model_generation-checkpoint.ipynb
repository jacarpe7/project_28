{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed imports from Pandas, Numpy, Pickle, Matplot, Keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "if os.path.exists(\"best_model.pkl\"): os.remove(\"best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading raw data\n",
    "path = 'MovementAAL/new_dataset/stream_0000'\n",
    "sequences = list()\n",
    "\n",
    "for i in range (1,9):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    values = df.values\n",
    "    sequences.append(values)\n",
    "\n",
    "path = 'MovementAAL/new_dataset/stream_000'\n",
    "\n",
    "for i in range(10, 99):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    sequences.append(values)\n",
    "\n",
    "path = 'MovementAAL/new_dataset/stream_00'\n",
    "\n",
    "for i in range(100, 200):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    sequences.append(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target values\n",
    "targets = pd.read_csv('MovementAAL/new_dataset/MovementAAL_target.csv')\n",
    "targets = targets.values[:200,1]\n",
    "print(len(targets))\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading grouping\n",
    "groups = pd.read_csv('MovementAAL/groups/MovementAAL_DatasetGroup.csv', header=0)\n",
    "groups = groups.values[:200,1]\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sequences = []\n",
    "for one_seq in sequences:\n",
    "    len_sequences.append(len(one_seq))\n",
    "print(pd.Series(len_sequences).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding the sequence with the values in last row to max length\n",
    "to_pad = 55\n",
    "new_seq = []\n",
    "for one_seq in sequences:\n",
    "    len_one_seq = len(one_seq)\n",
    "    last_val = one_seq[-1]\n",
    "    n = to_pad - len_one_seq\n",
    "   \n",
    "\n",
    "    to_concat = np.repeat(one_seq[-1], n).reshape(9, n).transpose()\n",
    "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
    "    new_seq.append(new_one_seq)\n",
    "final_seq = np.stack(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-rabbit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#truncate the sequence to length 60\n",
    "seq_len = 75\n",
    "final_seq=sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float', truncating='post')\n",
    "print(final_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data based on group 2\n",
    "train = [final_seq[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "#validation data based on group 1\n",
    "validation = [final_seq[i] for i in range(len(groups)) if groups[i]==1]\n",
    "#test data based on group 3\n",
    "test = [final_seq[i] for i in range(len(groups)-5) if groups[i]==3]\n",
    "\n",
    "#train target based on group 2\n",
    "train_target = [targets[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "#validation target based on group 1\n",
    "validation_target = [targets[i] for i in range(len(groups)) if groups[i]==1]\n",
    "#test target based on group 3\n",
    "test_target = [targets[i] for i in range(len(groups)) if groups[i]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating np.arrays for each dataset\n",
    "train = np.array(train)\n",
    "validation = np.array(validation)\n",
    "test = np.array(test)\n",
    "\n",
    "#training target data\n",
    "train_target = np.array(train_target)\n",
    "train_target = (train_target+1)/2\n",
    "\n",
    "#validation target\n",
    "validation_target = np.array(validation_target)\n",
    "validation_target = (validation_target+1)/2\n",
    "\n",
    "#test data and target test\n",
    "test_target = np.array(test_target)\n",
    "test_target = (test_target+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the LSTM to the model and printing the summary\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(seq_len, 9)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "chk = ModelCheckpoint('best_model.pkl', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.fit(train, train_target, epochs=80, batch_size=400, callbacks=[chk], validation_data=(validation,validation_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the exported pkl model and testing the accuracy score\n",
    "model = load_model('best_model.pkl')\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = model.predict_classes(test)\n",
    "print(test)\n",
    "print(test_preds)\n",
    "print(test_target)\n",
    "accuracy_score(test_target, test_preds)\n",
    "print(accuracy_score(test_target, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
