{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "departmental-operation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 54,504\n",
      "Trainable params: 54,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = tf.keras.models.load_model('/Users/Kelly/Desktop/Test/project_28/python_scripts/nine-sensor-model/lstm')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cardiac-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3  2 -2 ...  1  2  1]\n",
      "  [ 3  2 -2 ...  0  2  1]\n",
      "  [ 2  1 -1 ...  0 -1  0]\n",
      "  ...\n",
      "  [ 1  0  0 ... -4  2  2]\n",
      "  [ 1  0 -1 ...  1  0  1]\n",
      "  [ 1  0 -1 ...  1  0  0]]\n",
      "\n",
      " [[ 2  1 -1 ... -1 -1  1]\n",
      "  [ 2  1  1 ... -1 -1  1]\n",
      "  [ 3  1  0 ... -1  1  2]\n",
      "  ...\n",
      "  [ 2  0  1 ...  2  0  0]\n",
      "  [ 1 -1  1 ...  2  1  1]\n",
      "  [ 1  1  1 ...  2  1  1]]\n",
      "\n",
      " [[ 1  1  1 ... -2  0  0]\n",
      "  [ 1  1  0 ... -2  0  0]\n",
      "  [ 1  1  0 ... -2  1  0]\n",
      "  ...\n",
      "  [ 1  1  2 ... -1  1  2]\n",
      "  [ 2  0  0 ... -1  1  1]\n",
      "  [ 2  0  0 ... -1  1  1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1  0 -2 ...  1  1  0]\n",
      "  [-1  0 -1 ...  1  1  0]\n",
      "  [-1  0 -1 ...  2  1  0]\n",
      "  ...\n",
      "  [-1  1 -2 ...  1  1  2]\n",
      "  [ 0  0 -2 ...  1  1 -1]\n",
      "  [ 0  0 -3 ...  1  1  2]]\n",
      "\n",
      " [[ 0  1  0 ...  2  2  2]\n",
      "  [ 2  0  0 ...  1  2  3]\n",
      "  [ 2 -1  0 ...  2  2  3]\n",
      "  ...\n",
      "  [-1  0  0 ...  3  1  3]\n",
      "  [-1  0 -2 ...  3  1  1]\n",
      "  [-1  0 -2 ...  2  1  1]]\n",
      "\n",
      " [[ 3  2 -2 ...  2  2  2]\n",
      "  [ 3  2 -2 ...  2  2  2]\n",
      "  [ 1  2  0 ...  2  1  3]\n",
      "  ...\n",
      "  [ 1  0 -1 ...  1  1 -1]\n",
      "  [ 1  0 -1 ...  2  1 -1]\n",
      "  [ 0  1  1 ...  2  1  1]]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#loading raw data\n",
    "path = 'MovementAAL/new_dataset/stream_004'\n",
    "sequences = []\n",
    "\n",
    "for i in range (10,51):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path, header=0, usecols=[\"delta1\", \"delta2\", \"delta3\", \"delta4\", \"delta5\", \"delta6\", \"delta7\", \"delta8\", \"delta9\"])\n",
    "    values = df.values\n",
    "    sequences.append(values)\n",
    "    \n",
    "sequences = np.array(sequences)\n",
    "   \n",
    "#sequences = np.rot90(sequences[0])\n",
    "print(sequences)\n",
    "print(type(sequences))\n",
    "\n",
    "#[[[ 9x55 2d array ]],[[ 9x55 2d array ]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ambient-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  2, -2,  0,  1,  1,  1,  2,  1],\n",
       "       [ 3,  2, -2,  0,  0,  1,  0,  2,  1],\n",
       "       [ 2,  1, -1,  0,  0,  2,  0, -1,  0],\n",
       "       [ 2,  1, -1,  0, -1,  2, -1, -1,  0],\n",
       "       [ 2,  1, -1,  1, -1,  0, -1, -1,  0],\n",
       "       [ 1,  2,  1,  0,  1, -2,  0, -1,  1],\n",
       "       [ 1,  2,  1,  0,  1, -2,  0, -1,  1],\n",
       "       [ 1,  2,  1,  0,  1, -2,  0, -1, -1],\n",
       "       [ 1,  0,  2,  0,  1,  0,  1, -1, -1],\n",
       "       [-2,  2,  2, -2,  1,  0,  1, -1,  0],\n",
       "       [-2,  2,  2, -2,  1,  0,  1,  1,  2],\n",
       "       [ 2,  2,  5, -2,  2,  3, -1,  2,  3],\n",
       "       [ 2,  3,  5,  0,  3,  4, -1,  2,  3],\n",
       "       [ 2,  6,  5,  0,  8,  5, -1,  4,  5],\n",
       "       [ 9, 21,  3,  7, 19,  6,  4, 10,  5],\n",
       "       [13, 28,  3, 10, 30,  6,  5, 16,  7],\n",
       "       [18, 32,  0, 13, 40,  5,  5, 18,  7],\n",
       "       [18, 32,  0, 13, 46,  5,  5, 18,  7],\n",
       "       [18, 32,  0, 13, 46,  5,  5, 18,  7],\n",
       "       [18, 29,  0, 13, 46,  5,  5, 18,  7],\n",
       "       [18, 27,  0, 13, 47,  5,  5, 18,  7],\n",
       "       [18, 25,  0, 13, 47,  5,  5, 18,  7],\n",
       "       [18, 15,  4, 14, 47,  5,  5, 18,  7],\n",
       "       [16, 15,  6, 18, 29,  3, 10, 19,  6],\n",
       "       [16, 11,  6, 18, 29,  3, 10, 19,  6],\n",
       "       [16, 10,  6, 18, 29,  3, 10, 19,  6],\n",
       "       [16,  9,  6, 18, 29,  3, 10, 19,  6],\n",
       "       [16,  9,  6, 18, 29,  3, 10, 19,  6],\n",
       "       [16,  6,  6, 18, 29,  3, 10, 19,  6],\n",
       "       [ 8,  5,  3,  9,  8,  3,  7,  9,  4],\n",
       "       [ 6,  4,  0,  6,  6,  3,  4,  5,  1],\n",
       "       [ 6,  4,  0,  6,  5,  3,  4,  5,  1],\n",
       "       [ 6,  4,  0,  6,  4,  3,  4,  5,  1],\n",
       "       [ 6,  4,  0,  6,  3,  3,  4,  5,  1],\n",
       "       [ 6,  4,  0,  6,  3,  3,  4,  5,  1],\n",
       "       [ 6,  4,  0,  6,  2,  3,  4,  5,  1],\n",
       "       [ 3,  1,  0,  1,  2,  2,  1,  1,  1],\n",
       "       [ 3,  1,  2,  1,  1,  2,  1,  1,  1],\n",
       "       [ 2,  1, -1,  0,  1,  2, -1, -1,  1],\n",
       "       [ 2,  1, -1,  0,  1,  2, -1, -1,  1],\n",
       "       [ 2,  1, -1,  0,  1,  3, -1, -1,  0],\n",
       "       [ 1,  0, -1,  1,  0, -2, -1,  0,  0],\n",
       "       [ 1,  0,  0,  1, -1, -2,  0,  0, -1],\n",
       "       [ 1,  0,  0,  1, -1, -2,  1,  0, -1],\n",
       "       [ 2,  0,  0,  1,  0, -2,  1,  2,  2],\n",
       "       [ 2,  1,  0,  1,  0, -3,  0,  2,  2],\n",
       "       [ 2,  2,  0,  1,  0, -3,  0,  2,  2],\n",
       "       [ 1,  2, -1,  0,  1, -2,  0,  0,  1],\n",
       "       [ 0,  2, -1,  0,  1, -2,  0,  0,  1],\n",
       "       [ 0,  2, -1,  0,  1, -2,  0, -1,  1],\n",
       "       [ 1,  0,  0,  1,  0, -3,  0, -1,  3],\n",
       "       [ 1,  0,  0,  1, -2,  0, -4, -1,  3],\n",
       "       [ 1,  0,  0,  2, -2, -1, -4,  2,  2],\n",
       "       [ 1,  0, -1,  1, -1,  0,  1,  0,  1],\n",
       "       [ 1,  0, -1,  1,  0, -1,  1,  0,  0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "protective-tract",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 0 1 1 1 0 3 2 3 3 3 3 1 3 2 3 3 3 1 0 1 3 1 3 3 1 1 3 1 1 3 1 1 3\n",
      " 3 0 3 3]\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict_classes(sequences)\n",
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "restricted-temple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    for n in range(1,10):\n",
    "        filenames += ['sensor'+ str(n) + '-' + group + '.txt']\n",
    "\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/' + group + '-features.txt')\n",
    "    return X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\t# load all train\n",
    "\ttrainX, trainy = load_dataset_group('train', prefix)\n",
    "\tprint(trainX.shape, trainy.shape)\n",
    "\t# load all test\n",
    "\ttestX, testy = load_dataset_group('test', prefix)\n",
    "\tprint(testX.shape, testy.shape)\n",
    "\n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "\n",
    "\t# one hot encode y\n",
    "\ttrainy = to_categorical(trainy)\n",
    "\ttesty = to_categorical(testy)\n",
    "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\n",
    "\treturn trainX, trainy, testX, testy\n",
    "\n",
    "# load a list of files into a 3D array of [samples, timesteps, features]\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\t# print(\"Data: \", data)\n",
    "\t\tloaded.append(data)\n",
    "\t\t# print(\"loaded: \", loaded)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = dstack(loaded)\n",
    "\t\n",
    "\treturn loaded\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\t# print(\"load_file: \", dataframe.values)\n",
    "\treturn dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "leading-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 55, 9) (300, 1)\n",
      "(100, 55, 9) (100, 1)\n",
      "(300, 55, 9) (300, 4) (100, 55, 9) (100, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[[ 1  1 -2 ...  1  0  3]\n",
      "  [ 1  1  1 ...  1  0  3]\n",
      "  [ 1  1  1 ...  1  0  3]\n",
      "  ...\n",
      "  [ 2  0 -1 ...  1 -1  3]\n",
      "  [ 1  0 -1 ...  1 -1  2]\n",
      "  [ 1  0 -1 ...  1  1  2]]\n",
      "\n",
      " [[ 2  1 -1 ...  0  0  1]\n",
      "  [ 2  1  2 ...  1  0  0]\n",
      "  [ 0  1  2 ...  1  0  0]\n",
      "  ...\n",
      "  [ 0  0  0 ...  1  0  0]\n",
      "  [-1  0  0 ...  1 -1  0]\n",
      "  [-1  0  0 ...  1 -1 -1]]\n",
      "\n",
      " [[-1  1  2 ...  1  0  2]\n",
      "  [-1  1  2 ...  1  0  1]\n",
      "  [-1  1  2 ...  1  0  0]\n",
      "  ...\n",
      "  [ 4  1  1 ... -1  0  2]\n",
      "  [ 0 -1  1 ...  2  1  2]\n",
      "  [ 1  1  0 ...  1  2  2]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1  1 -1 ... -1  0  1]\n",
      "  [ 1  1  0 ...  0  0  2]\n",
      "  [ 0 -2  0 ...  1  0  2]\n",
      "  ...\n",
      "  [ 1 -1  0 ...  2 -1  0]\n",
      "  [ 1 -1 -1 ...  1  0  1]\n",
      "  [ 1  0 -1 ...  1  0  1]]\n",
      "\n",
      " [[ 0 -1 -1 ...  0 -1  0]\n",
      "  [ 0 -1 -1 ... -1 -1  0]\n",
      "  [ 0  1  0 ... -1 -1  0]\n",
      "  ...\n",
      "  [ 3  0  0 ... -1 -2 -1]\n",
      "  [ 1 -1 -3 ... -2 -1 -1]\n",
      "  [ 1  1 -3 ... -2 -1 -1]]\n",
      "\n",
      " [[-1 -1 -2 ... -2 -1 -2]\n",
      "  [ 0 -1 -2 ... -2 -1 -1]\n",
      "  [-1 -1 -2 ... -2  0 -1]\n",
      "  ...\n",
      "  [ 0  0 -2 ... -2 -2 -1]\n",
      "  [ 0  0 -3 ... -2 -2  0]\n",
      "  [ 0 -1 -3 ... -3 -2  0]]]\n",
      "[[ 1  1 -2  3  1  1  1  0  3]\n",
      " [ 1  1  1  1  1  2  1  0  3]\n",
      " [ 1  1  1  1  1  4  1  0  3]\n",
      " [ 1  1  0  1  1  4  0  0  2]\n",
      " [ 2  1  0  1  2  4  1  1  2]\n",
      " [ 2  1  3  2  1  3  0  0  2]\n",
      " [ 1  1  3  3  2  3  1  1  2]\n",
      " [ 1  1  2  3  3  2  0  1  2]\n",
      " [ 1  1  2  3  3  2  1  1  2]\n",
      " [ 3  3  2  2  5  2  1  4  6]\n",
      " [ 3  5  2  3  6  2  2  4  2]\n",
      " [ 5  9  3  4 13  4  2 11  6]\n",
      " [ 5 13  2  4 18  5  4 14  5]\n",
      " [ 5 18  4  6 23  5  4 20  6]\n",
      " [ 3 18  2  5 21  3  5 18  6]\n",
      " [ 3 18  2  5 21  3  5 16  6]\n",
      " [ 3 18  2  5 21  3  5 16  6]\n",
      " [ 3 18  2  5 21  3  5 15  6]\n",
      " [ 5 17  4  5 20  4  5 15  6]\n",
      " [ 5 16  4  5 20  4  3 15  6]\n",
      " [ 4 13  5  5 18  5  4 14  6]\n",
      " [ 3  9  5  4 18  5  4 10  5]\n",
      " [ 3  9  5  4 12  5  4 10  5]\n",
      " [ 3  9  5  4 12  5  4 10  5]\n",
      " [ 3  9  5  4 12  5  4 10  5]\n",
      " [ 3  9  5  4 12  5  4 10  5]\n",
      " [ 3  9  5  4 11  5  4 10  5]\n",
      " [ 4  9  3  4 10  5  3  7  5]\n",
      " [ 4  8  3  3  8  4  3  6  5]\n",
      " [ 3  6  2  5  6  2  3  5  5]\n",
      " [ 2  4  2  3  5  2  2  3  4]\n",
      " [ 2  2  2  3  3  2  1  3  3]\n",
      " [ 2  2  2  2  2  1  1  2  3]\n",
      " [ 2  2  0  2  2  0  1  2  3]\n",
      " [ 2 -1  1  1  2  0  1  2  2]\n",
      " [ 1 -1  0  1  1  0  1  0  1]\n",
      " [ 1  0 -1  1  2  0  1  0  1]\n",
      " [ 1  1 -1  1  1  0  1  1  0]\n",
      " [ 1  1 -1  1  0  0  1  1  2]\n",
      " [ 1  1 -1  1  0  2  1  2  0]\n",
      " [ 0  1 -1  1 -1  2 -1  0  2]\n",
      " [ 2  0  0  1  0  2 -1  0  0]\n",
      " [ 1  0  0  1  0  2  0  0  2]\n",
      " [ 1  0  0  0  1  2  0 -1  0]\n",
      " [ 0  0  0  1  1  2  0  0  2]\n",
      " [ 0  0  0  1  0  2  0  0  3]\n",
      " [ 1  0  0  1  0  2  0  0  3]\n",
      " [ 1  1  0  1  0  3  0  0  1]\n",
      " [ 0  1  0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  1  1  0]\n",
      " [ 0  1 -1  0  0 -1  1 -1  0]\n",
      " [ 2  0 -1  0  0 -1  1 -1  2]\n",
      " [ 2  0 -1  2  1  1  1 -1  3]\n",
      " [ 1  0 -1  2  0  1  1 -1  2]\n",
      " [ 1  0 -1  1  0  2  1  1  2]]\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = load_dataset()\n",
    "print(type(testX))\n",
    "print(type(testX[0]))\n",
    "print(testX)\n",
    "print(testX[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-algebra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-annotation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
